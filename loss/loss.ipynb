{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd2c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0edb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccfe6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.utils import intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2102966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d422d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, S, B, C):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        # S is split size of image (in paper 7),\n",
    "        # B is number of boxes (in paper 2), \n",
    "        # C is number off different classes      \n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # These are from Yolo paper\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "        # our prediction vector are coposed like [C classes ... , Pc1, x1, y1, w1, h1, Pc2, x2, y2, w2, h2]\n",
    "\n",
    "        # where Pc1 and Pc2 are the confidence parameters of the predicions and the others are to define \n",
    "        # boxes (center coordinates x and y, height and width of the boxes) \n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # predictions are shaped (BATCH_SIZE, S*S(C+B*5)) when inputted\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        # Calculate IoU for the two predicted bounding boxes with target bbox\n",
    "        iou_b1 = intersection_over_union(predictions[..., self.C+1:self.C+5], target[..., self.C+1:self.C+5])\n",
    "        iou_b2 = intersection_over_union(predictions[..., self.C+6:self.C+10], target[..., self.C+1:self.C+5])\n",
    "        # concatenate the result\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
    "\n",
    "        # Take the box with highest IoU out of the two prediction\n",
    "        # Note that bestbox will be indices of 0, 1 for which bbox was best(1 first, 0 second)\n",
    "        # torch.max gives us also the max value but we don't need that\n",
    "        iou_maxes, bestbox = torch.max(ious, dim=0)\n",
    "        exists_box = target[..., self.C].unsqueeze(3)  # in paper this is Iobj_i, in practice \n",
    "                                                       # it is the confidence parameter\n",
    "\n",
    "        \n",
    "        ### First factor depends on the correctness of the prediction coordinates ###\n",
    "\n",
    "        # Set boxes with no object in them to 0. We only take out one of the two \n",
    "        # predictions, which is the one with highest Iou calculated previously.\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                bestbox * predictions[..., self.C+6:self.C+10]\n",
    "                + (1 - bestbox) * predictions[..., self.C+1:self.C+5]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        box_targets = exists_box * target[..., self.C+1:self.C+5]\n",
    "\n",
    "        # Take sqrt of width, height of boxes to ensure that\n",
    "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4] + 1e-6)\n",
    "        )\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2),\n",
    "            torch.flatten(box_targets, end_dim=-2),\n",
    "        )\n",
    "\n",
    "        \n",
    "        ### Second factor depends on guessing object detection ###\n",
    "\n",
    "        # pred_box is the confidence score for the bbox with highest IoU\n",
    "        pred_box = (\n",
    "            bestbox * predictions[..., self.C+5:self.C+6] + (1 - bestbox) * predictions[..., self.C:self.C+1]\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box),\n",
    "            torch.flatten(exists_box * target[..., self.C:self.C+1]),\n",
    "        )\n",
    "\n",
    "        ### Third factor depends on failing object detection ###\n",
    "\n",
    "        #max_no_obj = torch.max(predictions[..., 20:21], predictions[..., 25:26])\n",
    "        #no_object_loss = self.mse(\n",
    "        #    torch.flatten((1 - exists_box) * max_no_obj, start_dim=1),\n",
    "        #    torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1),\n",
    "        #)\n",
    "\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., self.C:self.C+1], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., self.C:self.C+1], start_dim=1),\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., self.C+5:self.C+6], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., self.C:self.C+1], start_dim=1)\n",
    "        )\n",
    "\n",
    "        \n",
    "        ### Last factor depends on guessing the right class ###\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :self.C], end_dim=-2,),\n",
    "            torch.flatten(exists_box * target[..., :self.C], end_dim=-2,),\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss  # first two rows in paper\n",
    "            + object_loss  # third row in paper\n",
    "            + self.lambda_noobj * no_object_loss  # forth row\n",
    "            + class_loss  # fifth row\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd49126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
