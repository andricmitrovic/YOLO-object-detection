{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6195b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c62241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd33931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet18_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet18_CNN_BLOCK_8_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet50_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet50_CNN_BLOCK_8_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_vgg19_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_vgg19_unfrozenCNN_FC.ipynb\n"
     ]
    }
   ],
   "source": [
    "from models.model_resnet18_FC             import Yolov1 as Yolo_resnet18\n",
    "from models.model_resnet18_CNN_BLOCK_8_FC import Yolov1 as Yolo_resnet18_ft\n",
    "\n",
    "from models.model_resnet50_FC             import Yolov1 as Yolo_resnet50\n",
    "from models.model_resnet50_CNN_BLOCK_8_FC import Yolov1 as Yolo_resnet50_ft\n",
    "\n",
    "from models.model_vgg19_FC                import Yolov1 as Yolo_VGG19\n",
    "from models.model_vgg19_unfrozenCNN_FC    import Yolov1 as Yolo_VGG19_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf2f35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\dataset\\dataset.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\train\\utils.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\loss\\loss.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as FT\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import VOCDataset\n",
    "from train.utils import (\n",
    "    non_max_suppression,\n",
    "    mean_average_precision,\n",
    "    intersection_over_union,\n",
    "    cellboxes_to_boxes,\n",
    "    get_bboxes,\n",
    "    plot_image,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from loss.loss import YoloLoss\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4ffa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Hyperparameters etc. \n",
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "BATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\n",
    "WEIGHT_DECAY = 0\n",
    "EPOCHS = 300\n",
    "# NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FILE = \"overfit.pth.tar\"\n",
    "SAVE_MODEL_PATH = \"../output/trained_models/best_model.pth\"\n",
    "IMG_DIR = \"../dataset/data/preprocessed/training_images/\"\n",
    "LABEL_DIR = \"../dataset/labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb020e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, bboxes):\n",
    "        for t in self.transforms:\n",
    "            img, bboxes = t(img), bboxes\n",
    "\n",
    "        return img, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e218ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    mean_loss = []\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = sum(mean_loss)/len(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a1441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\andri/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026005983352661133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 102530333,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae85949f13c45058b02da367d220ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfrozen layer block 8:\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Unfrozen layer block 9:\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "\n",
      "Unfrozen layer block 10:\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Yolo_resnet50_ft(split_size=7, num_boxes=2, num_classes=1).to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "loss_fn = YoloLoss(S=7, B=2, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8eb83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42961c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VOCDataset(\n",
    "    \"../dataset/train_map.csv\",# link of the train.csv file\n",
    "    transform=transform,\n",
    "    img_dir=IMG_DIR,\n",
    "    label_dir=LABEL_DIR,\n",
    ")\n",
    "\n",
    "test_dataset = VOCDataset(\n",
    "    \"../dataset/val_map.csv\", \n",
    "    transform=transform, \n",
    "    img_dir=IMG_DIR, \n",
    "    label_dir=LABEL_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9eb6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d37e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping variables\n",
    "EARLY_STOPPING_LIMIT = 10\n",
    "epochs_since_last_improvement = 0\n",
    "best_loss = float('inf')\n",
    "best_model = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                               | 67/300 [09:53<34:01,  8.76s/it]"
     ]
    }
   ],
   "source": [
    "mean_loss_history = []\n",
    "mean_avg_prec_history = []\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # for x, y in train_loader:\n",
    "    #    x = x.to(DEVICE)\n",
    "    #    for idx in range(8):\n",
    "    #        bboxes = cellboxes_to_boxes(model(x))\n",
    "    #        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
    "    #        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n",
    "\n",
    "    #    import sys\n",
    "    #    sys.exit()\n",
    "\n",
    "    pred_boxes, target_boxes = get_bboxes(\n",
    "        train_loader, model, iou_threshold=0.5, threshold=0.4\n",
    "    )\n",
    "\n",
    "    mean_avg_prec = mean_average_precision(\n",
    "        pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n",
    "    )\n",
    "    # print(f\"Train mAP: {mean_avg_prec}\")\n",
    "\n",
    "    #if mean_avg_prec > 0.9:\n",
    "    #    checkpoint = {\n",
    "    #        \"state_dict\": model.state_dict(),\n",
    "    #        \"optimizer\": optimizer.state_dict(),\n",
    "    #    }\n",
    "    #    save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n",
    "    #    import time\n",
    "    #    time.sleep(10)\n",
    "\n",
    "    mean_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    #print(f\"Mean loss was {mean_loss}\")\n",
    "    \n",
    "    # append metrics\n",
    "    mean_avg_prec_history.append(mean_avg_prec)\n",
    "    mean_loss_history.append(mean_loss)\n",
    "\n",
    "    # early stopping\n",
    "    if mean_loss < best_loss:\n",
    "        epochs_since_last_improvement = 0\n",
    "        best_loss = mean_loss\n",
    "        best_model = model.state_dict() \n",
    "    else:\n",
    "        epochs_since_last_improvement += 1\n",
    "        if epochs_since_last_improvement >= EARLY_STOPPING_LIMIT:\n",
    "            print(f\"Early stopped at epoch {epoch}!\")\n",
    "            print(f\"Best model at epoch {epoch-epochs_since_last_improvement}!\")\n",
    "            model.load_state_dict(best_model)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(mean_avg_prec_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), mean_avg_prec_history, label = 'mean_avg_prec')\n",
    "plt.title(\"Mean training average precision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9839ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), mean_loss_history, label = 'mean_avg_prec')\n",
    "plt.title(\"Mean training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468429b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a model\n",
    "torch.save(model.state_dict(), SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b8934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
