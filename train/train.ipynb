{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148118b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520ce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2238ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet18_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet18_CNN_BLOCK_8_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet50_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_resnet50_CNN_BLOCK_8_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_vgg19_FC.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\models\\model_vgg19_unfrozenCNN_FC.ipynb\n"
     ]
    }
   ],
   "source": [
    "from models.model_resnet18_FC             import Yolov1 as Yolo_resnet18\n",
    "from models.model_resnet18_CNN_BLOCK_8_FC import Yolov1 as Yolo_resnet18_ft\n",
    "\n",
    "from models.model_resnet50_FC             import Yolov1 as Yolo_resnet50\n",
    "from models.model_resnet50_CNN_BLOCK_8_FC import Yolov1 as Yolo_resnet50_ft\n",
    "\n",
    "from models.model_vgg19_FC                import Yolov1 as Yolo_vgg19\n",
    "from models.model_vgg19_unfrozenCNN_FC    import Yolov1 as Yolo_vgg19_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf2f35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\dataset\\dataset.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\train\\utils.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\andri\\Documents\\Everything\\YOLO-object-detection\\train\\..\\loss\\loss.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as FT\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import VOCDataset\n",
    "from train.utils import (\n",
    "    non_max_suppression,\n",
    "    mean_average_precision,\n",
    "    intersection_over_union,\n",
    "    cellboxes_to_boxes,\n",
    "    get_bboxes,\n",
    "    plot_image,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    ")\n",
    "from loss.loss import YoloLoss\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4ffa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "LEARNING_RATE = 2e-5                      # try different learning rates\n",
    "# WEIGHT_DECAY = 0                        # try something here, why 0??\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "PIN_MEMORY = True\n",
    "SAVE_MODEL_PATH = \"../output/models/best_model.pth\"\n",
    "IMG_DIR = \"../dataset/VOC_dataset/VOC2012_train_val/VOC2012_train_val/JPEGImages/\"\n",
    "LABEL_TRAIN_DIR = \"../dataset/labels/train/\"\n",
    "LABEL_VAL_DIR = \"../dataset/labels/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb020e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, bboxes):\n",
    "        for t in self.transforms:\n",
    "            img, bboxes = t(img), bboxes\n",
    "\n",
    "        return img, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([transforms.Resize((224, 224)), transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e218ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    mean_loss = []\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = sum(mean_loss)/len(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4a8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_fn(val_loader, model, optimizer, loss_fn):\n",
    "    model.eval()\n",
    "    mean_loss = []\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(val_loader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "\n",
    "    mean_loss = sum(mean_loss)/len(mean_loss)\n",
    "        \n",
    "    model.train()\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a3d88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo parameters\n",
    "split_size = 7 # split size\n",
    "box_count = 2 # bounding boxes per split\n",
    "class_count = 20 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1d10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_models = [Yolo_resnet18(S=split_size, B=box_count, C=class_count).to(DEVICE),\n",
    "                    Yolo_vgg19(S=split_size, B=box_count, C=class_count).to(DEVICE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a1441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Yolo_resnet18(S=split_size, B=box_count, C=class_count).to(DEVICE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# loss_fn = YoloLoss(S=split_size, B=box_count, C=class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c42961c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VOCDataset(\n",
    "    transform=transform,\n",
    "    img_dir=IMG_DIR,\n",
    "    label_dir=LABEL_TRAIN_DIR,\n",
    "    S=split_size, \n",
    "    B=box_count, \n",
    "    C=class_count\n",
    ")\n",
    "\n",
    "val_dataset = VOCDataset(\n",
    "    transform=transform, \n",
    "    img_dir=IMG_DIR, \n",
    "    label_dir=LABEL_VAL_DIR,\n",
    "    S=split_size, \n",
    "    B=box_count, \n",
    "    C=class_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9eb6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d37e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # early stopping variables\n",
    "# EARLY_STOPPING_LIMIT = 100\n",
    "# epochs_since_last_improvement = 0\n",
    "# best_loss = float('inf')\n",
    "# best_model = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Š                                                                             | 1/100 [06:21<10:29:30, 381.53s/it]"
     ]
    }
   ],
   "source": [
    "model_mean_loss_history_train = {}\n",
    "model_mean_avg_prec_history_train = {}\n",
    "model_mean_loss_history_val = {}\n",
    "model_mean_avg_prec_history_val = {}\n",
    "\n",
    "for model in candidate_models:  \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = YoloLoss(S=split_size, B=box_count, C=class_count)\n",
    "\n",
    "    mean_loss_history_train = []\n",
    "    mean_avg_prec_history_train = []\n",
    "    mean_loss_history_val = []\n",
    "    mean_avg_prec_history_val = []\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        pred_boxes, target_boxes = get_bboxes(train_loader, model, iou_threshold=0.5, threshold=0.4)\n",
    "        mean_avg_prec_train = mean_average_precision(pred_boxes, target_boxes, iou_threshold=0.5)\n",
    "        # print(f\"Train mAP: {mean_avg_prec}\")\n",
    "        mean_loss_train = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "        #print(f\"Mean loss was {mean_loss}\")\n",
    "\n",
    "        # if EPOCHS % 10:\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            pred_boxes, target_boxes = get_bboxes(val_loader, model, iou_threshold=0.5, threshold=0.4)\n",
    "            mean_avg_prec_val = mean_average_precision(pred_boxes, target_boxes, iou_threshold=0.5)\n",
    "            mean_loss_val = val_fn(val_loader, model, optimizer, loss_fn)\n",
    "\n",
    "        # append metrics\n",
    "        mean_avg_prec_history_train.append(mean_avg_prec_train)\n",
    "        mean_loss_history_train.append(mean_loss_train)\n",
    "        mean_avg_prec_history_val.append(mean_avg_prec_val)\n",
    "        mean_loss_history_val.append(mean_loss_val)\n",
    "        \n",
    "    model_mean_loss_history_train[str(model)]     = mean_loss_history_train\n",
    "    model_mean_avg_prec_history_train[str(model)] = mean_avg_prec_history_train\n",
    "    model_mean_loss_history_val[str(model)]       = mean_loss_history_val\n",
    "    model_mean_avg_prec_history_val[str(model)]   = mean_avg_prec_history_val\n",
    "\n",
    "#     # early stopping\n",
    "#     if mean_loss_val < best_loss:\n",
    "#         epochs_since_last_improvement = 0\n",
    "#         best_loss = mean_loss_val\n",
    "#         best_model = model.state_dict() \n",
    "#     else:\n",
    "#         epochs_since_last_improvement += 1\n",
    "#         if epochs_since_last_improvement >= EARLY_STOPPING_LIMIT:\n",
    "#             print(f\"Early stopped at epoch {epoch}!\")\n",
    "#             print(f\"Best model at epoch {epoch-epochs_since_last_improvement}!\")\n",
    "#             model.load_state_dict(best_model)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "for model in candidate_models:\n",
    "    \n",
    "    ax[0].plot(range(EPOCHS), model_mean_avg_prec_history_train[str(model)], label = f'train {str(model)}')\n",
    "    ax[0].plot(range(EPOCHS), model_mean_avg_prec_history_val[str(model)], label = f'val {str(model)}')\n",
    "    #ax[0, 0].title(\"Mean trainining average precision\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    ax[1].plot(range(EPOCHS), model_mean_loss_history_train[str(model)], label = f'train {str(model)}')\n",
    "    ax[1].plot(range(EPOCHS), model_mean_loss_history_val[str(model)], label = f'val {str(model)}')\n",
    "    #plt.title(\"Mean training loss\")\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick best model\n",
    "best_model = None\n",
    "best_precision = 0\n",
    "for model in candidate_models:\n",
    "    model_precision = model_mean_avg_prec_history_val[str(model)][-1]\n",
    "    if model_precision > best_precision:\n",
    "        best_model = model\n",
    "        best_precision = model_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best model: {best_model}')\n",
    "print(f'Precision: {round(best_precision.item(), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions on train data\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        out = best_model(x)\n",
    "        #classes, confidences = get_class_confidences(out)\n",
    "        #break\n",
    "        bboxes = cellboxes_to_boxes(out)\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            bboxes_nms = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4)\n",
    "            plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes_nms)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions on validation data\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        out = best_model(x)\n",
    "        bboxes = cellboxes_to_boxes(out)\n",
    "        for idx in range(BATCH_SIZE):\n",
    "            bboxes_nms = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4)\n",
    "            plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes_nms)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468429b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a model\n",
    "torch.save(best_model.state_dict(), SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b8934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
